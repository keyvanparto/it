---
layout: post
title: "Lezione 2: Ingredienti per costruire una Macchina di Apprendimento"
description: "Esploriamo i componenti essenziali per un primo prototipo di macchina di apprendimento"
media_subpath: /img/lesson_2
image:
  path: /lesson_2.jpg
date: 2024-11-02
math: true
categories: [Machine Learning]
tags: [machine-learning, introduction, learning-algorithms, data-science, ai-basics, model-training, ml-theory]     # TAG names should always be lowercase
---
Nella **[prima lezione](../lezione_1)**, abbiamo esplorato l'idea di costruire una *learning machine*, un sistema in grado di apprendere dal passato per prevedere il futuro. Abbiamo discusso il ruolo dei dati osservabili $$ x $$ e delle variabili obiettivo $$ y $$, come possono essere rappresentati e i problemi computazionali che possono derivare da questa rappresentazione. Inoltre abbiamo visto come la correlazione tra questi dati ci permetta di fare stime, pur consapevoli della presenza di rumore e della nostra conoscenza incompleta del sistema originale.

<blockquote class="prompt-tip">
Ti ricordi? <br>Abbiamo visto che sia l'input \( \underline{x} \) sia il target \( \underline{y} \) possono essere rappresentati come vettori di elementi appartenenti rispettivamente a \( \mathbb{R}^d \) e a \( \mathbb{R}^p \), dove \( d \) e \( p \)  rappresentano le dimensioni del vettore, ovvero il numero di componenti. </blockquote>

In questa **seconda lezione**, andremo oltre, analizzando gli ingredienti fondamentali per costruire una *learning machine*.

Veniamo quindi al sodo.


<h2 id="predictor"><span class="me-2">Funzione di Predizione</span><a href="#predictor" class="anchor text-muted"></a></h2>

Il nostro obiettivo è costruire un modello di apprendimento, ovvero una learning machine, che possa essere rappresentata in questo modo:

$$
 \underline{\hat{y}}= \underline{f}(\underline{x})
$$

Poiché $$\underline{\hat{y}}$$ è un vettore, possiamo pensare di predire ciascun elemento $ \hat{y_i}$ singolarmente, utilizzando una funzione specifica per ogni componente:

$$
 \hat{y_i} \in \mathbb{R} = f_i(\underline{x})
$$

Quindi, il problema generale che vogliamo risolvere si riduce a:

$$
 \hat{y} \in \mathbb{R} = f(\underline{x})
$$

ovvero, a stimare un valore reale dato un vettore di possibilità.

Ma visto che stiamo costruendo la nostra prima macchina, perché non semplifichiamo ulteriormente?

Invece di prendere $$\underline{x} $$ come vettore, consideriamolo un semplice scalare $$x$$:

$$
 \hat{y} = f({x})
$$

<blockquote class="prompt-info"> Per la nostra prima macchina di apprendimento consideriamo: <br>
$$ x \in \mathbb{R}, \quad \hat{y} \in \mathbb{R} $$


Stiamo quindi ipotizzando di avere a che fare soltanto con scalari (laddove  di solito abbiamo vettori o roba ancora peggiore). </blockquote>

Tornando al nostro modello, ora sappiamo cosa mettere nella nostra learning machine:

![Light mode only](/learningmachine.png){: .light }
![Dark mode only](/learningmachinedark.png){: .dark }
_Stiamo raffinando il nostro modello_

Ma, in ultima istanza, come definisco la funzione?

Ci sono infiniti modi per definirla, perché ci sono infinite funzioni che, preso un input, danno un output, quindi devo scegliere.

Esiste una scelta ottimale?

No!

Perché secondo il teorema del **No Free lunch**, per le condizioni che abbiamo imposto inizialmente (ovvero conosciamo solo l'input $$ x $$ e non sappiamo nulla né del sistema né del rumore), qualsiasi scelta facciamo può essere ottima in un caso e pessima in un altro. Per predire il futuro con una complessità computazionale ragionevole, dobbiamo quindi fare dei compromessi.

<blockquote class="prompt-danger">
<strong>No free lunch</strong>: qualsiasi cosa facciamo non sarà ottimale, infatti ci accontentiamo della scelta che funziona meglio rispetto a tutte quelle fatte in precedenza.
</blockquote>

Quindi scegliamo la funzione più semplice che conosciamo, ovvero:

$$
\hat{y} = f(x) = \sum_{i=0}^p c_i x^i 
$$


Infatti, con un polinomio di grado abbastanza alto, possiamo approssimare qualsiasi funzione vogliamo.


<h2 id="loss-function"><span class="me-2">Funzione di Perdita</span><a href="#loss-function" class="anchor text-muted"></a></h2>

 Ora devo definire meglio cosa intendo per buona approssimazione $$ \hat{y} \approx y $$.
 
 Definisco una **funzione di perdita**:
 
 $$ l(\hat{y}, y) \rightarrow \mathbb{R} $$

La funzione di perdita prende in input le previsioni del modello e i valori effettivi della realtà (target) e restituisce un numero reale che rappresenta l'errore (la perdita) associata a quelle previsioni.

Come la scelgo?

Non posso più rifarmi ai modelli matematici di approssimazione che conosciamo (Taylor o Fourier) perché siamo partiti da diverse premesse.

Scegliamo l'**errore quadratico medio**:

$$ l(f(x), y) = (y - f(x))^2 $$

Questa funzione di errore ci piace particolarmente poiché è derivabile infinite volte e non presenta discontinuità.

<h2 id="dataset"><span class="me-2">Dataset</span><a href="#dataset" class="anchor text-muted"></a></h2>


Infine, ecco i nostri dati (le nostre osservazioni del mondo reale):

$$ D_n = \{ (x_1, y_1), \ldots, (x_n, y_n) \} $$

dove $$ n $$ è il numero di osservazioni.

<h2 id="nutshell"><span class="me-2">In poche parole</span><a href="#nutshell" class="anchor text-muted"></a></h2>

<blockquote class="prompt-tip">
{% raw %}
Gli ingredienti per la nostra prima macchina di apprendimento:<br><br>
1. <strong>Funzione di Predizione</strong>: <div id="eq-polynomial"> 
$$
\hat{y} = f(x) = \sum_{i=0}^p c_i x^i \tag{1}
$$
</div>
2. <strong>Funzione di Perdita</strong>: <div id="eq-loss">
$$
l(f(x), y) = (y - f(x))^2 \tag{2}
$$
</div>
3. <strong>Dataset</strong>: $$ D_n = \{ (x_1, y_1), \dots, (x_n, y_n) \} $$

{% endraw %}
</blockquote>

<blockquote class="prompt-warning">
{% raw %}
\( p \) e \( c_i \) sono da trovare.<br> \( f \) e \( l \) li abbiamo scelti.
{% endraw %}
</blockquote>

Abbiamo ora tutti gli ingredienti fondamentali per costruire una prima versione della nostra learning machine: una funzione di predizione, una funzione di perdita e un dataset di osservazioni.

Tuttavia, sapere quali funzioni utilizzare e con quali parametri non è sufficiente: dobbiamo anche essere in grado di trovare i valori migliori per questi parametri.

Nel prossimo articolo esploreremo come farlo, analizzando diversi metodi per risolvere i sistemi lineari e ottimizzare la nostra macchina.

Alla prossima!
