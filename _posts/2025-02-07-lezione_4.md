---
layout: post
title: "Lezione 4: Figli del caos"
description: "Perché non sarà la statistica classica a salvarci dal battito d'ali di una farfalla"
media_subpath: /img/lesson_4
image:
  path: /lesson_4.jpg
date: 2025-02-07
math: true
categories: [Machine Learning]
tags: [machine-learning, introduction, learning-algorithms, data-science, ai-basics, model-training, ml-theory]     # TAG names should always be lowercase
---

{% include disclaimer.html %}

Nella **[scorsa lezione](../lezione_3)**, abbiamo provato a giocare con alcuni ingredienti chiave del machine learning: gli iperparametri. Abbiamo capito cosa ci differenzia dalle macchine e abbiamo provato a ridurre la complessità del mondo in equazioni risolvibili con una dose massiccia di potenza computazionale.

Ma i dati sono davvero così prevedibili? Cosa succede quando l'ordine apparente cede il passo alla natura frammentaria della realtà? In questa lezione proveremo a squarciare questo velo.

Entriamo subito nel vivo.

Supponiamo che i miei dati siano generati da questa funzione oracolo:

![Light mode only](/function_light.png){: .light }
![Dark mode only](/function_dark.png){: .dark }


Quello che sto facendo definendo questa funzione è rimuovere l'ipotesi del machine learning secondo cui non conosco come funzioni il sistema. In questo caso so come funziona perché conosco la funzione che genera i dati.

Immaginiamo quindi che l'oracolo generi dei dati e che questi dati siano soggetti ad un certo rumore:

![Light mode only](/points_light.png){: .light }
![Dark mode only](/points_dark.png){: .dark }

Adesso da questi dati voglio usare mia funzione predittiva $$\hat{y} = f(x) = \sum_{i=0}^p c_i x^i $$ per trovare una funzione che più approssima quei dati.

La domanda che ci poniamo adesso è: qual è il miglior $$p$$?

Vedremo che la miglior soluzione può essere $$0$$, $$1$$, $$2$$.

Ma da cosa dipende?

Dipende da:

1. il numero $$n$$ di campioni a nostra disposizione.
2. il rumore.

Facciamo un esempio per capire meglio.

Supponiamo che

$$p = n - 1$$

ovvero il grado del polinomio sia uguale al numero dei campioni.

Dalla **[scorsa lezione](../lezione_3/#c)** dovresti ricordare che calcolare:

$$
\min_{\underline{c}} \|X \underline{c} - \underline{y}\|^2
$$

equivale a cercare i coefficienti $$c_i$$ che minimizzano la distanza fra i dati reali e le mie previsioni.

Se il grado del polinomio è uguale al numero dei dati, il minimo che ci aspettiamo di vedere è questo:

$$
\min_{\underline{c}} \|X \underline{c} - \underline{y}\|^2 = 0,  \forall  D_n
$$

perché quando scegliamo un polinomio di grado $$p = n - 1$$, stiamo impostando il problema in modo tale che il polinomio passi esattamente attraverso tutti i punti dati[^1].

Nel caso il numero di punti sia $$n = 3$$, la situazione è questa:

![Light mode only](/second_function_light.png){: .light }
![Dark mode only](/second_function_dark.png){: .dark }
_Fate largo! Passo attraverso ai dati e quindi sono perfetto! Oh, no..._

La funzione si discosta radicalmente dalla funzione che sappiamo per ipotesi essere quella corretta, ovvero la funzione oracolo $$y=x^2$$.

E questo non è affatto quello che vorremmo, giusto?

Paradossalmente (ma in realtà, come vedremo, non troppo paradossalmente), avremmo avuto un risultato più efficace scegliendo un polinomio di grado 1, ovvero una retta:

![Light mode only](/third_function_light.png){: .light }
![Dark mode only](/third_function_dark.png){: .dark }
_La retta approssima molto meglio la funzione oracolo rispetto alla curva che passa lungo i dati_

Questo significa che minimizzare lungo i dati non è una cosa troppo furba da fare, perché invece di adattare i dati, adatto il rumore dei dati.

Per capire perché ciò avviene, dobbiamo entrare nel dominio della statistica.

## Statistica

Dimentichiamoci delle notazioni finora introdotte e ridefiniamone di nuove.

Da una variabile $$X$$ campioniamo una serie di osservazioni.

$$ X \rightarrow  x_1, \ldots, x_n$$

- $$X$$ rappresenta quindi un fenomeno incerto che stiamo studiando. 
- Il campione $$x_1, \ldots, x_n$$ è un insieme di $$n$$ valori che osserviamo nella pratica, indipendenti e identicamente distribuiti (**i.i.d.**).

<blockquote class="prompt-tip">

Osservazioni <strong>i.i.d</strong> significa:<br><br>

1. <strong>Indipendenti</strong>: il valore di un’osservazione non influenza gli altri. <br><br>

2. <strong>Identicamente distribuite</strong>: tutte le osservazioni provengono dalla stessa distribuzione di probabilità.<br><br>

</blockquote>

Ad esempio, immaginiamo di voler stimare quante volte un bambino di 3 anni chiede "Perché?" in un'ora.

- $$X$$ è la variabile casuale che rappresenta il numero di "Perché?" chiesti da un bambino in un'ora.
- $$x_1, x_2, \ldots, x_n$$ rappresentano ciascuno il numero di perché detti da ogni generico bambino in un'ora. Ad esempio:
  $$
  x_1 = 20, \; x_2 = 30, \; x_3 = 15, \; x_4 = 25, \; x_5 = 35
  $$

In questo contesto i.i.d. significa che:
- assumiamo che i dati siano **indipendenti**, ovvero che il numero di "Perché?" chiesti da un bambino non influenzi il comportamento degli altri bambini.
- assumiamo che i dati siano **identicamente distribuiti**, ovvero che ogni bambino proviene dalla stessa *popolazione* (ad esempio bambini di 3 anni curiosi).

Queste ipotesi sono fondamentali per poter applicare i concetti che vedremo.

### Valore atteso

Sempre dalla statistica sappiamo che $$\mu$$, la **media teorica**, o valore atteso, è:

$$
\mu = \mathbb{E}_X[X] = \int_D x \cdot p(x) \, dx
$$

Questo ci dice che la media teorica $$\mu$$ è calcolata pesando ogni valore possibile di $$X$$ ovvero $$x$$ con la sua probabilità $$p(x)$$. $$D$$ è il dominio di distribuzione di probabilità.
Nel nostro caso, $$\mu$$ rappresenta il numero medio di "Perché?" chiesti da un bambino **nell'intera popolazione**, non solo nel campione. Perciò l'integrale.

Però, l'unico modo che ho di stimare $$\mu$$ è tramite la **media empirica** perché non posso stimare tutti i valori possibili, ma solo quelli che conosco.

### Media empirica

La **media empirica**, o campionaria, è calcolata come:

$$
\bar{X} = \frac{1}{n} \sum_{i=1}^n x_i
$$

Ad esempio: 
con $$n = 5$$ bambini:

$$
\bar{X} = \frac{1}{5} (x_1 + x_2 + x_3 + x_4 + x_5) = \frac{1}{5} (20 + 30 + 15 + 25 + 35) = \frac{125}{5} = 25
$$

Quindi, stimiamo che un bambino chieda in media 25 "Perché?" in un'ora.

### Stimatore

La media empirica $$\bar{X}$$ è uno stimatore non polarizzato della media teorica $$\mu$$:

$$
\mathbb{E}_{\bar{X}}[\bar{X}] = \mu
$$

Cosa significa?

Significa che se campioniamo $$n$$ campioni, calcoliamo il valor medio, ripetiamo questa procedura un numero infinito di volte e, infine, calcoliamo il valor medio di tutte queste medie, otteniamo il valore vero della media teorica.

Vediamo di dimostrarlo.

1. L'aspettativa della media campionaria è:

   $$
   \mathbb{E}_{\bar{X}}[\bar{X}] = \mathbb{E}_{x_1, \ldots, x_n} \left[\bar{X}\right] = \mathbb{E}_{x_1, \ldots, x_n} \left[\frac{1}{n} \sum_{i=1}^n x_i\right] 
   $$

2. Siccome i dati sono i.i.d. posso scambiare la sommatoria con il valore atteso:

   $$
   \mathbb{E}_{x_1, \ldots, x_n} \left[\frac{1}{n} \sum_{i=1}^n x_i\right]  = \frac{1}{n} \sum_{i=1}^n \mathbb{E}_{x_i}[x_i]
   $$

3. E siccome gli $$x_i$$ sono identicamente distribuiti posso dire che:

   $$
   \frac{1}{n} \sum_{i=1}^n \mathbb{E}_{x_i}[x_i]= \frac{1}{n} \cdot n \cdot \mu 
   $$

4. Quindi:

   $$
   \mathbb{E}_{\bar{X}}[\bar{X}] = \mu
   $$

Questo dimostra che il valore atteso della media empirica $$\bar{X}$$ coincide con la media teorica $$\mu$$. 

---

Ma questo non è sufficiente.

<blockquote class="prompt-info">
In statistica, per ottenere una stima completa e affidabile, abbiamo bisogno di considerare <strong>tre quantità fondamentali</strong>:<br><br>

&nbsp;&nbsp;&nbsp;&nbsp;1. <strong>Stimatore</strong>: che abbiamo identificato nella media empirica grazie al fatto che è uno stimatore non polarizzato di \( \mu \), la media teorica o valore atteso.<br><br>

&nbsp;&nbsp;&nbsp;&nbsp;2. <strong>Accuratezza</strong>: rappresenta quanto una singola stima campionaria \(\bar{X}\) è vicina alla media teorica \( \mu \). L'accuratezza dipende dalla <strong>varianza dello stimatore</strong>,
che deve essere sufficientemente piccola per garantire che le stime siano concentrate attorno a \( \mu \).<br><br>

&nbsp;&nbsp;&nbsp;&nbsp;3. <strong>Fiducia</strong>: riguarda la probabilità che una stima campionaria \(\bar{X}\) cada entro un intervallo specifico attorno a \( \mu \). Questo concetto è alla base della costruzione degli intervalli di confidenza, che ci permettono di quantificare l'affidabilità delle stime.<br>

</blockquote>

### Accuratezza

Abbiamo dimostrato che la media empirica $$\bar{X}$$ è uno stimatore non polarizzato della media teorica $$\mu$$.
Questo significa che, in media, il valore atteso dello stimatore $$\bar{X}$$ coincide con $$\mu$$, ovvero non tende sistematicamente a sovrastimare o sottostimare il parametro vero.
Tuttavia, la proprietà di non polarizzazione non è sufficiente per garantire che ogni singola stima campionaria $$\bar{X}$$ sia vicina a $$\mu$$.

Questa vicinanza è ciò che chiamiamo **accuratezza**.

Per capire quanto uno stimatore sia accurato, dobbiamo considerare la sua **varianza**.

#### Varianza

La varianza dello stimatore è ciò che determina quanto possono essere ampie le fluttuazioni delle singole stime campionarie. Quantifica, cioè, quanto si disperdono i dati rispetto alla media.
Se i campioni $$({x_1, \ldots, x_n})$$ sono molto vicini al valor medio $$\mu$$, la varianza sarà piccola.
Se invece i campioni sono molto distanti dalla media, la varianza sarà grande.

In altre parole, più grande è la varianza, più i dati sono sparpagliati; più è piccola, più i dati sono concentrati attorno alla media.

Tornando al nostro esempio dei bambini curiosi (o stressanti, se preferite), supponiamo di osservare due gruppi distinti. Nel primo, ogni bambino chiede "Perché?" circa 25 volte, con piccole variazioni. Nel secondo, alcuni bambini chiedono solo 5 "Perché?", mentre altri ne chiedono 50. Il primo gruppo avrà una varianza più bassa, perché i dati sono più concentrati attorno alla media, mentre il secondo gruppo avrà una varianza più alta, riflettendo una maggiore dispersione.

La varianza di una variabile casuale $$X$$ è definita come:

$$
\sigma_X^2 = \mathbb{E}_X \left[ (X - \mu)^2 \right] =
$$

$$
=\mathbb{E}_X \left[ X^2 \right] - 2 \mathbb{E}_X \left[ X \mu \right] + \mathbb{E}_X \left[ \mu^2 \right]
$$

Ma per la linearità dell'operatore del valore atteso, $$\mu$$ può uscire fuori:

$$
2 \mathbb{E}_X \left[ X \mu \right] = 2 \mu \mathbb{E}_X \left[ X\right] = 2 \mu\mu = 2 \mu^2
$$

Analogamente:

$$
\mathbb{E}_X \left[ \mu^2 \right] = \mu^2
$$

Quindi, la varianza diventa:

$$
\sigma_X^2 = \mathbb{E}_X \left[ (X - \mu)^2 \right] = \mathbb{E}_X \left[ X^2 \right] - 2 \mu^2 + \mu^2 = \mathbb{E}_X \left[ X^2 \right] - \mu^2
$$

La varianza ci serve per dimostrare la **Legge dei Grandi Numeri**. Questa legge afferma che, man mano che aumenta il numero di dati, lo stimatore $$\bar{X}$$ sarà sempre più vicino alla media teorica $$\mu$$.

Per dimostrarlo, calcoliamo la **varianza di $$\bar{X}$$**.

$$
\sigma_{\bar{X}}^2 = \mathbb{E}_{\bar{X}} \left[\bar{X}^2\right] - \left(\mathbb{E}_{\bar{X}} \left[\bar{X}\right]\right)^2 = \mathbb{E}_{x_1, \ldots, x_n} \left\{ \frac{1}{n^2} \sum_{i=1}^n \sum_{j=1}^n x_i \cdot x_j \right\} - \mu^2 = \textcolor{#007FFF}{\bullet}
$$

Concentriamoci sulla doppia sommatoria. Possiamo constatare che:

$$i = j \rightarrow x_i^2 $$

$$i \neq j \rightarrow x_i \cdot x_j $$

Essendo una doppia sommatoria, la sua rappresentazione è una matrice cosiffatta:

$$
\begin{bmatrix}
x_1^2 & \cdots & x_i x_j & \cdots & x_1 x_n \\
\vdots & \ddots & \vdots & & \vdots \\
x_i x_j & \cdots & (x_i)^2 & \cdots & x_i x_j \\
\vdots & & \vdots & \ddots & \vdots \\
x_n x_1 & \cdots & x_i x_j & \cdots & x_n^2
\end{bmatrix}
$$

dove:

1. lungo la diagonale principale abbiamo gli elementi $$x_i^2 $$ che sono $$n$$ come gli elementi della sommatoria.

2. ovunque tranne che nella diagonale principale abbiamo gli elementi $$x_i \cdot x_j$$ che saranno quindi uguali al numero degli elementi della matrice che è un $$n \times n = n^2$$ a cui dobbiamo sottrarre gli elementi della diagonale principale che abbiamo detto essere $$n$$. Quindi il numero di elementi $$x_i \cdot x_j$$ è $$n^2 - n$$.

Adesso separiamo i membri fuori dalla diagonale, da quelli sulla diagonale:

$$\textcolor{#007FFF}{\bullet} = \frac{1}{n^2} \sum_{i=1}^n \sum_{\substack{j=1 \\ j \neq i}}^n \underbrace{\mathbb{E}_{x_i, x_j}(x_i \cdot x_j)}_{\mu^2} + \frac{1}{n^2} \sum_{i=1}^n \underbrace{\mathbb{E}_{x_i}[x_i^2]}_{\mathbb{E}_X[x^2]} - \mu^2 = \textcolor{\green}{\bullet}$$

Posso affermare che:

1. $$\mathbb{E}_{x_i, x_j}(x_i \cdot x_j) = \mu^2 $$ perché $$x_i$$ e $$x_j$$ sono indipendenti e quindi:

   $$\mathbb{E}_{x_i, x_j}(x_i \cdot x_j) = \mathbb{E}[x_i] \cdot \mathbb{E}[x_j] = \mu \cdot \mu = \mu^2$$

2. $$\mathbb{E}_{x_i}[x_i^2] = \mathbb{E}_X[x^2]$$ perché tutte le $$x$$ sono i.i.d..

E ricordando che per $$i \neq j $$ gli elementi sono $$n^2-n$$ e che per $$i = j $$ gli elementi sono $$n$$, possiamo scrivere che:

$$
\textcolor{\green}{\bullet} = \frac{n^2 - n}{n^2} \mu^2 + \frac{n}{n^2} \mathbb{E}_X[x^2] - \mu^2 =
$$

$$
= \frac{\cancel{n^2} - n \cancel{-n^2}}{n^\cancel{2}} \mu^2 + \frac{1}{n} \mathbb{E}_X[x^2] =
$$


$$
= \frac{1}{n} \left(\mathbb{E}_X[x^2] - \mu^2\right)
$$

E per definizione:

$$
= \frac{\sigma_X^2}{n}.
$$

Quindi abbiamo ottenuto che:

$$
\sigma_{\bar{X}}^2 = \frac{\sigma_X^2}{n}.
$$

Questo risultato è un tassello fondamentale per provare la **Legge dei Grandi Numeri**, perché rende evidente che aumentando il numero di campioni, la varianza del nostro stimatore tenderà a zero.
In altre parole, il nostro stimatore $$\bar{X}$$ converge a $$\mu$$. Più dati raccogliamo, più è probabile che ciò che misuriamo si avvicini a ciò che vogliamo misurare.

Ad esempio, se osserviamo solo cinque bambini, la stima del numero medio di "Perché?" potrebbe essere influenzata da variazioni casuali. Ad esempio potrebbero essere stati tutti distratti da uno scoiattolo fuori dalla finestra. Oppure potresti aver beccato il gruppo di bambini super organizzati con una lista scritta a mano di 50 "Perché?" preparati in anticipo. Ma se osserviamo 100 o 1000 bambini, le oscillazioni casuali si compensano, e la nostra stima diventa sempre più precisa, avvicinandosi sempre di più alla media teorica $$\mu$$.

Tuttavia, questo risultato ci dice solo che, con un numero sufficiente di campioni, lo stimatore sarà vicino alla media teorica. Non ci dice **quanto** siamo vicini a ciò che vogliamo misurare.

Abbiamo quindi uno stimatore corretto (non polarizzato) e una misura della convergenza ($$\bar{X} \to \mu$$), ma ci manca ancora un ingrediente fondamentale: **la fiducia** nella nostra stima.

### Fiducia

La **fiducia** nella nostra stima si riferisce alla probabilità che lo stimatore campionario $$\bar{X}$$ cada entro un intervallo specifico attorno alla media teorica $$\mu$$. Questo concetto è legato alla costruzione di intervalli di confidenza, che ci permettono di dire **quanto ci possiamo fidare** delle nostre stime.

Per analizzare questa fiducia, ci concentriamo sulla probabilità che $$\bar{X}$$ si discosti da $$\mu$$ di un valore maggiore di una soglia $$\epsilon$$:

$$
P\{ |\bar{X} - \mu| \geq \epsilon \}
$$

Utilizzando la definizione di varianza, sappiamo che:

$$
\sigma_{\bar{X}}^2 = \int_{-\infty}^{\infty} (\bar{X} - \mu)^2 \, p(\bar{X}) \, d\bar{X} \geq
$$

Visto che stiamo integrando una funzione positiva possiamo dire che questa quantità maggiora:

$$
\geq \int_{|\bar{X} - \mu| > \epsilon} (\bar{X} - \mu)^2 \, p(\bar{X}) \, d\bar{X}
$$

Stiamo integrando su $$\vert\bar{X} - \mu\vert > \epsilon$$ perché ci stiamo focalizzando su eventi in cui lo stimatore si discosta significativamente dalla media teorica.

Ovvero, in buona sostanza, è come se stessi integrando la mia funzione in un intervallo di questo tipo:

![Light mode only](/integration_light.png){: .light }
![Dark mode only](/integration_dark.png){: .dark }

Sostituiamo $$ (\bar{X} - \mu)^2 $$ con il minimo valore possibile in quella regione, ovvero $$\epsilon^2$$. Otteniamo:

$$
\int_{|\bar{X} - \mu| > \epsilon} (\bar{X} - \mu)^2 \, p(\bar{X}) \, d\bar{X} \geq
$$

Visto che $$\vert\bar{X} - \mu\vert > \epsilon$$, questa quantità maggiora:

$$ 
\geq 
\int_{|\bar{X} - \mu| > \epsilon} \epsilon^2 p(\bar{X}) \, d\bar{X} =
$$

$$ 
=\epsilon^2 \int_{|\bar{X} - \mu| > \epsilon} p(\bar{X}) \, d\bar{X}
$$

Questo integrale è proprio la probabilità che $$\vert\bar{X} - \mu\vert \geq \epsilon$$.
Questo in quanto sto integrando la densità di probabilità di $$\bar{X}$$ solo quando $$\vert\bar{X} - \mu\vert \geq \epsilon$$, ovvero per definizione di densità di probabilità.
Quindi possiamo riscrivere:

$$
\sigma_{\bar{X}}^2 \geq \epsilon^2 P\{ |\bar{X} - \mu| \geq \epsilon \}
$$

Da questa relazione, possiamo isolare la probabilità e ottenere una disuguaglianza importante, nota come la **disuguaglianza di Chebyshev**:

$$
P\{ |\bar{X} - \mu| \geq \epsilon \} \leq \frac{\sigma_{\bar{X}}^2}{\epsilon^2}
$$

<blockquote class="prompt-tip">

Poiché sappiamo che \( \sigma_{\bar{X}}^2 = \frac{\sigma_X^2}{n} \), possiamo ulteriormente scrivere:

$$
P\{ |\bar{X} - \mu| \geq \epsilon \} \leq \frac{\sigma_X^2}{n \epsilon^2}
$$

che è la <strong>Legge dei Grandi Numeri </strong>.
</blockquote>

Adesso supponiamo che $$X$$ sia limitata, ovvero che $$X \in [0, 1] $$. Del resto tutto quel che conosciamo, a parte l'universo, è limitato.
E ad onor del vero, dobbiamo ancora provare che l'universo sia infinito.

Possiamo scrivere che:

$$
P\{ |\bar{X} - \mu| \geq \epsilon \} \leq \frac{\sigma_X^2}{n \epsilon^2} \leq \frac{1}{n \epsilon^2}
$$

Questo perché la varianza sarà sempre contenuta entro i limiti imposti dal dominio dei valori che la variabile può assumere.

E adesso abbiamo tutto quello che ci serve:

<div id="eq-big-numbers"> 
$$
P\left\{ |\underbrace{\bar{X}}_{\text{Stimatore}} - \mu| \geq \underbrace{\epsilon}_{\text{Accuratezza}} \right\} \leq \underbrace{\frac{1}{n \epsilon^2}}_{\text{Fiducia}} \tag{1}
$$
</div>

Quello che sto affermando è questo:

![Light mode only](/confidence_light.png){: .light }
![Dark mode only](/confidence_dark.png){: .dark }

Ovvero, per stimare la media teorica $$\mu$$, eseguo diverse misurazioni (rappresentate dai puntini sui segmenti). Ogni misurazione fornisce una stima della media ottenuta da un campione.

Per ogni stima, calcolo un intervallo di fiducia (i segmenti orizzontali).
Questi intervalli rappresentano l'incertezza della stima: un range di valori entro il quale $$\mu$$ dovrebbe trovarsi con una certa probabilità (ad esempio, il 99%).

La maggior parte degli intervalli include $$\mu$$. Soltanto una piccola percentuale degli intervalli non include $$\mu$$ (ad esempio il segmento verde).  
Questo indica che la stima è corretta rispetto al livello di confidenza scelto.

Un segmento più corto indica maggiore precisione: la stima è più vicina alla media teorica $$\mu$$ e l'incertezza è minore.

Un intervallo di confidenza più lungo indica che abbiamo meno certezza sulla posizione della media teorica $$\mu$$: la stima è meno precisa.

<blockquote class="prompt-tip">

Fiducia e accuratezza sono connesse: se voglio più fiducia ho bisogno di meno accuratezza; se voglio più accuratezza ho bisogno di meno fiducia.
</blockquote>

Quest'ultima considerazione risulta ancora più evidente se riscriviamo la [$$ (1) $$](#eq-big-numbers):

$$
P\left\{ |\underbrace{\bar{X}}_{\text{Stimatore}} - \mu| \geq \underbrace{\epsilon}_{\text{Accuratezza}} \right\} \leq \frac{\sigma_X^2}{n \epsilon^2} \leq \underbrace{\frac{1}{n \epsilon^2}}_{\text{Fiducia}} = \delta 
$$

e ricaviamo, in modo implicito, la seguente relazione:

$$
\epsilon = \sqrt{\frac{1}{n \delta}}
$$

O, in modo esplicito:

$$
|\bar{X} - \mu| \underset{1 < \delta}{\leq} \sqrt{\frac{1}{n \delta}}
$$

Ovvero la media campionaria $$\bar{X}$$ si trova entro una distanza di $$ \sqrt{\frac{1}{n \delta}} $$ dalla media teorica $$\mu$$ con probabilità $$1 - \delta$$.

O, ancora:

<div id="eq-confidence-bound"> 
$$
\mu \underset{(1 - \delta)}{\leq} \bar{X} + \sqrt{\frac{1}{n \delta}} \quad \quad X \in [0, 1], \quad x_1, \dots, x_n \rightarrow i.i.d. \tag{2}
$$
</div>

Se $$\mu$$ è la probabilità che, con la somministrazione di un certo farmaco, le persone muoiano, e io somministro il farmaco a 1000 persone, allora posso dire che questa probabilità è minore o uguale a quella che ho misurato su 1000 persone più $$\sqrt{\frac{1}{1000 \cdot \delta}}$$ dove $$\delta$$ è la fiducia che desidero. 

Ad esempio, se voglio il 99% di accuratezza, imposto $$\delta = 0.01$$. 

## Il batter d’ali di una farfalla

Ma perché abbiamo fatto tutto questo?

Per dimostrare che tutto quello che abbiamo fatto finora per costruire la learning machine è basato sulla formula [$$ (2) $$](#eq-confidence-bound).

Quindi ripartiamo dai nostri **[ingredienti](../lezione_2/)** e ritorniamo nel dominio del machine learning. Avevamo:

**Dataset**: $$ D_n = \{ (x_1, y_1), \dots, (x_n, y_n) \}, \quad x \in \mathbb{R},\quad y \in \mathbb{R} $$

**Funzione di predizione**: $$ \hat{y} = f(x) = \sum_{i=0}^p c_i x^i $$

**Funzione di Perdita**: $$ l(f(x), y) = (y - f(x))^2 $$

E volevamo minimizzare l'errore sui dati con questa:

<div id="eq-min"> 
$$
\frac{1}{n} \sum_{i=1}^n (y_i - f(x_i))^2 \tag{3}
$$
</div>

che è uno stimatore di questa:

$$
\mathbb{E}_{x, y} \left( y - f(x) \right)^2
$$

Ma adesso concentriamoci e guardiamole meglio, ovvero con le notazioni che abbiamo visto in questa lezione di statistica:

$$
\underbrace{ \frac{1}{n} \sum_{i=1}^n \underbrace{({y_i - f(x_i)})^2}_{x_i}}_{\bar{X}} 
\quad \longleftrightarrow \quad 
\underbrace{\mathbb{E}_{x, y} \underbrace{(y - f(x))^2}_{X}}_{\mu}
$$

<blockquote class="prompt-warning">
Le notazioni sotto alle graffe si riferiscono alle notazioni di statistica che abbiamo introdotto in questa lezione.<br>

Le formule senza le graffe invece rappresentano le notazioni delle lezioni precedenti di machine learning.<br>

Si tratta di due domini <strong>distinti</strong>!
</blockquote>

Quindi sembra esserci una corrispondenza con la statistica! Ma attenzione.

Della quantità di [sinistra](#eq-min) noi avevamo calcolato il minimo. Perché l'avevamo fatto?

Perché avevamo ipotizzato che se fossimo riusciti a ridurre gli errori sui nostri dati, allora anche l'errore rispetto alla popolazione sarebbe stato più piccolo.

Questo ragionamento si basa sull'idea che la media empirica (calcolata sui dati) è un buon estimatore della vera media (quella sulla distribuzione reale dei dati).

Tuttavia, non abbiamo verificato le ipotesi sottostanti per poterlo affermare.

Infatti, le ipotesi che stiamo facendo in statistica implicano che gli errori (ovvero le discrepanze tra le previsioni del modello e i valori osservati) siano i.i.d. (indipendenti e identicamente distribuiti).

Questo significa che anche i dati debbano essere i.i.d. perché dati non i.i.d. non potrebbero mai generare errori i.i.d..

Se questa ipotesi non è soddisfatta, non possiamo garantire che l'errore empirico calcolato sui dati raccolti sia un buon estimatore dell'errore vero (quello che il modello farebbe su dati nuovi).

Ad esempio, senza indipendenza non potremmo provare la Legge dei Grandi Numeri. L'indipendenza garantisce che ogni dato porti informazione nuova e non sia ridondante rispetto agli altri.
Infatti, se ci fosse dipendenza fra i dati non importerebbe quante volte misuro perché misurerei sempre la stessa informazione.

Identicamente distribuiti, invece, significa che il sistema non sta cambiando nel tempo. E per predirre il futuro abbiamo bisogno esattamente di questo: che il futuro sia simile al passato.
Ed è esattamente questo che significa simile: identicamente distribuiti.

Ma nella realtà i dati non sono né indipendenti né identicamente distribuiti.

Nella realtà i dati sono figli del caos.

Il batter d'ali di una farfalla in Brasile può provocare un tornado in Texas[^2].

Lo spostamento di un singolo elettrone per un miliardesimo di centimetro, a un momento dato, potrebbe significare la morte o la salvezza di un uomo un anno dopo[^3].

## Conclusione

Ora supponiamo di non fare alcun apprendimento sui dati, cioè di non minimizzare rispetto ai parametri $$\underline{c}$$ del modello.

In un contesto in cui i dati sono i.i.d., possiamo dire che l'errore empirico (calcolato sui dati) è un buon estimatore dell'errore vero (calcolato sull'intera popolazione).

Questo è analogo a prendere un sistema, applicarci una funzione di perdita e misurarne la performance: è come misurare la temperatura in una stanza o testare una macchina e verificare se funziona o meno. In questi casi stiamo utilizzando soltanto la statistica perché stiamo semplicemente applicando una misurazione di qualche tipo.

Tuttavia, il caso interessante è quello in cui impariamo dai dati.

In questo scenario, non ci limitiamo a misurare, ma cerchiamo di **imparare**: vogliamo trovare la funzione (o il modello) che lavora meglio sui dati osservati.

Questo processo cambia le regole del gioco:

1. Proviamo una funzione (cioè un'ipotesi o un modello).
2. Misuriamo l'errore empirico su quei dati.
3. Modifichiamo la funzione in base ai risultati, cercando di minimizzare l'errore.
4. Ripetiamo il processo.

La teoria alla base del machine learning non si basa sulla statistica classica, ma sulla teoria dell’**apprendimento statistico**.

Questa differenza è fondamentale. Implica che dobbiamo modificare il nostro approccio, ovvero la [$$ (2) $$](#eq-confidence-bound), per tenere conto del processo di apprendimento.

Perché nel momento in cui minimizziamo la [funzione di costo](#eq-min) per adattare un modello ai dati, rompiamo l’assunzione di indipendenza: gli errori non sono più indipendenti tra loro.

Questo avviene perché il modello ottimizzato è costruito tenendo conto di tutti i dati contemporaneamente, quindi l’errore su un dato punto è influenzato da quello sugli altri punti.

Questa interdipendenza introduce una complessità maggiore rispetto all’errore empirico: non possiamo più considerarlo direttamente come un semplice estimatore dell’errore vero.

Minimizzare l’errore empirico può sembrare una soluzione naturale, ma nasconde una trappola: l’eccessivo adattamento ai dati. Questo è il punto in cui statistica e machine learning divergono. La statistica classica si limita a descrivere fenomeni osservati, mentre il machine learning cerca di imparare da questi fenomeni per prevedere l'ignoto. Ed è esattamente questa che approfondiremo nella prossima lezione.

Alla prossima!

---

### Un pizzico di ironia

Se un bambino supera **30 "Perché?"** in un’ora, possiamo considerarlo un caso "fuori scala". A questo punto, possiamo iniziare a prevedere le risposte dell’adulto basandoci su alcuni principi di probabilità e statistica:

1. **"Perché sì!"**: Risposta breve ed efficiente, ottima quando il tempo medio di elaborazione dell’adulto si riduce dopo i primi 20 "Perché?".

2. **"Perché me lo chiedi?"**: Strategia inquisitoria che mima il comportamento del bambino per cercare di confonderlo. È efficace nel 50% dei casi per indurre una pausa (ma attenzione: potrebbe anche generare un loop infinito di "Perché?").

3. **"Perché Babbo Natale non esiste!"**: l'ultima spiaggia, la mossa disperata quando l'adulto ha ormai esaurito ogni risorsa e pazienza. Certo, può interrompere bruscamente il flusso infinito di "Perché?", ma attenzione: il rischio di scatenare un pianto a dirotto è dell'88% e il bambino potrebbe denunciarvi.

Secondo i dati raccolti nel nostro studio, il numero medio di "Perché?" è $$25$$. Superare i $$35$$ "Perché?" si verifica in meno del **16% dei casi**. Il numero più alto di "Perché" registrati in un'ora è di 3600. In quest'ultimo caso, si dice che l'adulto abbia raggiunto uno stato mistico, abbandonando ogni speranza e rispondendo semplicemente: "Perché l'universo è infinito" prima di librarsi in aria e scomparire all'orizzonte alla velocità della luce, implodendo, 8 minuti e 20 secondi dopo, nella stella che oggi chiamiamo Sole.

---

[^1]: Poiché $$p = n - 1$$, la matrice $$X$$ è quadrata (dimensione $$n \times n$$) e invertibile (ipotizzando che i punti $$x_i$$ siano distinti). Questo significa che il sistema $$ X'X\underline{c} = X'\underline{y} $$ ha una soluzione unica: $$\underline{c} = (X'X)^{-1} X'\underline{y}$$ ovvero la soluzione $$c_i$$ coincide con i coefficienti del polinomio interpolante che passa esattamente per tutti i punti dati.

[^2]: Celebre espressione utilizzata da Edward Lorenz.

[^3]: Alan Turing, *Macchine calcolatrici e intelligenza*, 1950